{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c2bc17f-75c9-4b8a-b1a8-8a073cff8e2c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Notice!!! Please use search function to check all the cells with \"notice\" keywords, those are sanity checks and potential manual variable changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f95d7ed0-8d72-451f-8413-9845198fd1f0",
     "showTitle": true,
     "title": "Notice!!! Need to check the end_date and file_date everytime"
    }
   },
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "# Please define the target Timestamp for the end date for the generation of COVID patients dataset\n",
    "# Notice: Format: YYYY-MM-DD\n",
    "# Current set to 2021-12-10\n",
    "############################################################################################################\n",
    "# check to make sure they are consistent\n",
    "# Previous dates used:\n",
    "# 1. \"2021-12-31\", \"20211231\"\n",
    "# 2. \"2022-02-18\", \"20220218\"\n",
    "# 3. end_date, file_date = \"2021-12-25\", \"20211225\"\n",
    "# end_date, file_date = \"2021-12-21\", \"20211221\"\n",
    "\n",
    "start_date, end_date, file_date = \"2020-03-01\", \"2021-12-25\", \"20211225_Lancet_bmi\"\n",
    "# register it so can be directly used in the following SQL statement\n",
    "spark.conf.set(\"enddate.var\", end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16996a15-5b9c-4242-99d9-3959fb24c30d",
     "showTitle": true,
     "title": "Install necessary packages or use python classL instance"
    }
   },
   "outputs": [],
   "source": [
    "#pip install xgboost\n",
    "#pip install joblib\n",
    "#pip install scikit-learn\n",
    "#pip install shap\n",
    "\n",
    "### Keep the follow cell empty can copy all the install commands and run them one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1dddf9-c789-4350-a689-8f5f1dae00ee",
     "showTitle": true,
     "title": "Copy from above and run here one by one"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a11a334-6f4a-440b-8f44-af603258bc8a",
     "showTitle": true,
     "title": "Import needed python packages"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _reverse_window(order, start, length):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _reverse_window_score_gain(masks, order, start, length):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _mask_delta_score(m1, m2):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/links.py:5: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def identity(x):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/links.py:10: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _identity_inverse(x):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/links.py:15: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def logit(x):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/links.py:20: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _logit_inverse(x):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def lower_credit(i, value, M, values, clustering):\nThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\nThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "## Scikit-learn related\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "## from sklearn import cross_validation, metrics   #Additional scklearn functions, deprecated since version 0.18\n",
    "## from sklearn.grid_search import GridSearchCV   #!!!the grid search package that has issue, dont use it\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from scipy import interp\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "########################################\n",
    "## Import those from pyspark.ml\n",
    "import pyspark.ml\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad2a350-d3c4-4176-8620-77560ed8d0b6",
     "showTitle": true,
     "title": "Read the file into a pyspark dataframe"
    }
   },
   "outputs": [],
   "source": [
    "imids_training_df = spark.sql(\"\"\"SELECT * FROM rdp_phi_sandbox.qw_IMID_COVID_trainset_cond_med_vax_{}\"\"\".format(file_date)) \n",
    "# imids_training_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0642bec-2970-468f-9256-6d22a99ebdf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# imids_training_df.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e26c9b93-b5d9-4ba0-b7d3-9c25ea7bd202",
     "showTitle": true,
     "title": "Temp solution, for some reason there are duplicated records for the same patient"
    }
   },
   "outputs": [],
   "source": [
    "imids_training_df = imids_training_df.dropDuplicates()\n",
    "# imids_training_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8969ad8-e0d7-4911-b441-f174ad1b5835",
     "showTitle": true,
     "title": "Drop not needed columns, rearrange them, then rename them"
    }
   },
   "outputs": [],
   "source": [
    "## Drop not used columns\n",
    "col_to_drop = ('age_range', 'ethnicity', 'race1', 'race_v2', 'ethnicity_race', 'CVX_name', 'decided_index_date', 'CVX_name')\n",
    "imids_training_df = imids_training_df.drop(*col_to_drop)\n",
    "\n",
    "## rename IMIDs drugs columns\n",
    "imids_training_df = imids_training_df.withColumnRenamed('prior_91_days_hydroxychloroquine_logic', 'hydroxychloroquine').withColumnRenamed('prior_91_days_methotrexate_logic', 'methotrexate')\\\n",
    ".withColumnRenamed('prior_91_days_leflunomide_teriflunomide_logic', 'leflunomide_teriflunomide').withColumnRenamed('prior_91_days_5_ASAa_logic', '5_ASA')\\\n",
    ".withColumnRenamed('prior_91_days_azathioprine_logic', 'azathioprine').withColumnRenamed('prior_91_days_mercaptopurine_logic', 'mercaptopurine')\\\n",
    ".withColumnRenamed('prior_91_days_mitoxantrone_logic', 'mitoxantrone')\\\n",
    ".withColumnRenamed('prior_91_days_mycophenolate_logic', 'mycophenolate').withColumnRenamed('prior_91_days_calcineurin_inhibitor_logic', 'calcineurin_inhibitor')\\\n",
    ".withColumnRenamed('prior_91_days_TNF_alpha_inhibitor_logic', 'TNF_alpha_inhibitor').withColumnRenamed('prior_91_days_fumarates_logic', 'fumarates')\\\n",
    ".withColumnRenamed('prior_91_days_interferons_logic', 'interferons').withColumnRenamed('prior_91_days_alkylating_agent_logic', 'alkylating_agent')\\\n",
    ".withColumnRenamed('prior_91_days_hydroxyurea_logic', 'hydroxyurea').withColumnRenamed('prior_91_days_dapsone_logic', 'dapsone')\\\n",
    ".withColumnRenamed('prior_91_days_cladribine_logic', 'cladribine').withColumnRenamed('prior_91_days_IL1_inhibitor_logic', 'IL1_inhibitor')\\\n",
    ".withColumnRenamed('prior_91_days_IL6_inhibitor_logic', 'IL6_inhibitor').withColumnRenamed('prior_91_days_IL12_23_inhibitor_logic', 'IL12_23_inhibitor')\\\n",
    ".withColumnRenamed('prior_91_days_IL17_inhibitor_logic', 'IL17_inhibitor')\\\n",
    ".withColumnRenamed('prior_91_days_IL23_inhibitor_logic', 'IL23_inhibitor')\\\n",
    ".withColumnRenamed('prior_91_days_abatacept_logic', 'abatacept').withColumnRenamed('prior_91_days_anti_BLyS_logic', 'anti_BLyS')\\\n",
    ".withColumnRenamed('prior_91_days_S1P_receptor_modulator_logic', 'S1P_receptor_modulator').withColumnRenamed('prior_91_days_JAK_inhibitor_logic', 'JAK_inhibitor')\\\n",
    ".withColumnRenamed('prior_91_days_integrin_inhibitor_logic', 'integrin_inhibitor').withColumnRenamed('prior_91_days_PDE4i_targeted_synthetic_logic', 'PDE4i_targeted_synthetic')\\\n",
    ".withColumnRenamed('prior_91_days_anti_CD20_logic', 'anti_CD20').withColumnRenamed('prior_91_days_anti_CD52_logic', 'anti_CD52')\\\n",
    ".withColumnRenamed('prior_91_days_budesonide_logic', 'budesonide').withColumnRenamed('prior_91_days_systemic_glucocorticoids_logic', 'systemic_glucocorticoids')\\\n",
    ".withColumnRenamed('after_10_days_monoclonal_antibody_covid_19_logic', 'monoclonal_antibody_covid_19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3db3106b-86ab-40c5-93ae-138f4d3431ca",
     "showTitle": true,
     "title": "Filter the positive patient here"
    }
   },
   "outputs": [],
   "source": [
    "## Temp solution, filter the positive patient here\n",
    "pos_df = imids_training_df.filter(imids_training_df['results'] == \"Positive\")\n",
    "\n",
    "## convert to pandas dataframe\n",
    "# imids_training_pd_df = imids_training_onlyPos_df.toPandas()\n",
    " \n",
    "## col names before dropping any\n",
    "# list(imids_training_pd_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a0fefb1-869d-4386-97d4-f54261844489",
     "showTitle": true,
     "title": "Dummy one-hot encode those categorical features"
    }
   },
   "outputs": [],
   "source": [
    "## One hot-encode sex\n",
    "categ = pos_df.select('sex').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "exprs = [F.when(F.col('sex') == cat,1).otherwise(0)\\\n",
    "            .alias(str(\"sex_\" + cat)) for cat in categ]\n",
    "pos_one_hot_df = pos_df.select(pos_df.columns + exprs)\n",
    "\n",
    "## Fill none values in the vaccination column\n",
    "pos_one_hot_df = pos_one_hot_df.fillna({'Vaccination_status':'Not'})\n",
    "\n",
    "## One hot-encode vaccination\n",
    "categ = pos_one_hot_df.select('Vaccination_status').distinct().rdd.flatMap(lambda x:x).collect()\n",
    "exprs = [F.when(F.col('Vaccination_status') == cat,1).otherwise(0)\\\n",
    "            .alias(str(\"vaccination_\" + cat)) for cat in categ]\n",
    "pos_one_hot_df = pos_one_hot_df.select(pos_one_hot_df.columns + exprs)\n",
    "\n",
    "## Drop not needed cols and original cols\n",
    "pos_one_hot_df = pos_one_hot_df.drop(\"sex\").drop(\"sex_Female\").drop(\"sex_Unknown\").drop(\"Vaccination_status\").drop(\"vaccination_Not\")\n",
    "\n",
    "## change the name of those vaccination related columns\n",
    "pos_one_hot_df = pos_one_hot_df.withColumnRenamed('vaccination_Fully', 'fully_vaccinated').withColumnRenamed('vaccination_Booster', 'boosted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3565aa47-ebed-4cc2-9a77-e4d58c35a376",
     "showTitle": true,
     "title": "Use min-max to normalize those continues features (need to do it after train/test split)"
    }
   },
   "outputs": [],
   "source": [
    "# ## Manually define the min max process\n",
    "# from pyspark.sql.functions import max, min, mean, col\n",
    "\n",
    "# max_age, min_age = pos_one_hot_df.select(max(\"age\"), min(\"age\")).first()\n",
    "# pos_one_hot_minmax_df = pos_one_hot_df.withColumn(\"age_normalized\", (col(\"age\") - min_age) / (max_age - min_age) )\n",
    "# pos_one_hot_minmax_df = pos_one_hot_minmax_df.drop(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36905c56-310d-429a-9700-c4710adfa7d6",
     "showTitle": true,
     "title": "Excluding patients on monoclonal antibody"
    }
   },
   "outputs": [],
   "source": [
    "# ## get the data where monoclonal_antibody_covid_19 = 0\n",
    "# pos_one_hot_noAntibody_df = pos_one_hot_df.where(pos_one_hot_df.monoclonal_antibody_covid_19 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d05d074e-0435-4932-841a-b62b2c30ffc7",
     "showTitle": true,
     "title": "Rearrange columns and set index for pyspark df"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pos_one_hot_df.select(\"*\")\n",
    "train_df = train_df.drop(\"pat_id\").drop(\"results\")\n",
    "\n",
    "## Drop SVI and geocoding features due to high missing percentage\n",
    "## list: 'SVI_Socioeconomic', 'SVI_Household_Composition_Disability', 'SVI_Minority_Status_Language', 'SVI_Housing_Type_Transportation', 'SVI', 'Metro_area', 'Low_education', 'Low_employment',\n",
    "## not including 'obesity'\n",
    "\n",
    "train_df = train_df.select('patient_id', 'hospitalized_after_positive','IMV_after_positive','death_after_positive',\n",
    "  'age', 'BMI', 'sex_Male',\n",
    "  'hypertension', 'diabetes_type1and2', 'atrial_fibrillation', 'coronary_artery_disease', 'heart_failure', 'chronic_kidney_disease', 'copd', 'chronic_liver_disease', 'malignant_neoplastic_disease', 'asthma', 'HIV', 'history_transplant', 'stroke', 'opioid_dependence', 'fully_vaccinated', 'boosted', \n",
    " 'ibd', 'rheumatoid_arthritis', 'multiple_sclerosis','psoriatic_arthritis', 'psoriasis', 'systemic_sclerosis', 'spondyloarthritis', 'systemic_lupus', 'vasculitis', 'sarcoidosis', 'APS', 'sjogren_syndrome',\n",
    " 'hydroxychloroquine',\n",
    " 'methotrexate',\n",
    " 'leflunomide_teriflunomide',\n",
    " '5_ASA',\n",
    " 'azathioprine',\n",
    " 'mercaptopurine',\n",
    " 'mitoxantrone',\n",
    " 'mycophenolate',\n",
    " 'calcineurin_inhibitor',\n",
    " 'TNF_alpha_inhibitor',\n",
    " 'fumarates',\n",
    " 'interferons',\n",
    " 'alkylating_agent',\n",
    " 'hydroxyurea',\n",
    " 'dapsone',\n",
    " 'cladribine',\n",
    " 'IL1_inhibitor',\n",
    " 'IL6_inhibitor',\n",
    " 'IL12_23_inhibitor',\n",
    " 'IL17_inhibitor',\n",
    " 'IL23_inhibitor',\n",
    " 'abatacept',\n",
    " 'anti_BLyS',\n",
    " 'S1P_receptor_modulator',\n",
    " 'JAK_inhibitor',\n",
    " 'integrin_inhibitor',\n",
    " 'PDE4i_targeted_synthetic',\n",
    " 'anti_CD20',\n",
    " 'anti_CD52',\n",
    " 'budesonide',\n",
    " 'systemic_glucocorticoids',\n",
    " 'monoclonal_antibody_covid_19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6536e59f-5d73-4202-a35d-1e725fa4a7b3",
     "showTitle": true,
     "title": "Convert to pandas df and set index"
    }
   },
   "outputs": [],
   "source": [
    "train_pd_df = train_df.toPandas()\n",
    "## change the patient id col to be the index of the training data\n",
    "train_pd_df = train_pd_df.set_index(\"patient_id\")\n",
    "# display(train_pd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42495b42-474c-41fc-9153-e81a90918ace",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Training data preprocessing and test data split\n",
    "* Assign features for training data to X\n",
    "* Assign response to Y\n",
    "* Define the number of CV & random seed used for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08063a68-1684-4cce-9a4e-2ddc7fd5e4b2",
     "showTitle": true,
     "title": "Save a backup of the training dataset for this run"
    }
   },
   "outputs": [],
   "source": [
    "# ### Uncomment to save table as backup for publications\n",
    "# spark.sql(\"\"\"DROP TABLE IF EXISTS rdp_phi_sandbox.qw_IMIDs_COVID_paper_train_data_processed_{}\"\"\".format(file_date))\n",
    "# table_name = \"rdp_phi_sandbox.qw_IMIDs_COVID_paper_train_data_processed_{}\".format(file_date)\n",
    "# ## Convert into Spark DataFrame\n",
    "# spark_df_one_hot_encoded = spark.createDataFrame(df_one_hot_encoded)\n",
    "\n",
    "# ## Write the table\n",
    "# # spark_df_one_hot_encoded.write.mode(\"overwrite\").saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "654431d2-507b-4db8-b157-48a4c573115d",
     "showTitle": true,
     "title": "Define helper functions"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#Random search CV method\n",
    "#and\n",
    "#Multi class roc_auc score method\n",
    "########################################################\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from time import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "###############################################################################################\n",
    "#Binary class roc auc score method\n",
    "#input: y_true, true labels from test fold\n",
    "#       y_score, predicted probability on test fold\n",
    "#       average, string, [None, ‘micro’, ‘macro’ (default), ‘samples’, ‘weighted’]\n",
    "#                'macro': Calculate metrics for each label, and find their unweighted mean. \n",
    "#                This does not take label imbalance into account.\n",
    "#                'weighted': Calculate metrics for each label, and find their average, \n",
    "#                weighted by support (the number of true instances for each label).\n",
    "#output: auroc value for each class\n",
    "#############################################################################################\n",
    "def binary_class_roc_auc_score(y_true, y_score, average=\"weighted\"):\n",
    "\n",
    "    return roc_auc_score(y_true, y_score, average=average)\n",
    "\n",
    "binaryclass_score = make_scorer(binary_class_roc_auc_score, needs_threshold = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2673dd0e-8e87-4baa-b37f-c89e2ff2f921",
     "showTitle": true,
     "title": "Pandas df change col names"
    }
   },
   "outputs": [],
   "source": [
    "## not including: , 'obesity'\n",
    "train_pd_df.columns = ['hospitalized_after_positive', 'IMV_after_positive', 'death_after_positive', 'age', 'BMI', 'sex:male', 'hypertension', 'diabetes (type 1+2)', 'atrial fibrillation', 'coronary artery disease', 'heart failure', 'chronic kidney disease', 'COPD', 'chronic liver disease', 'malignant neoplastic disease', 'asthma', 'HIV', 'history of transplant', 'stroke', 'opioid dependence', 'fully vaccinated', 'boosted', \n",
    " 'inflammatory bowel disease', 'rheumatoid arthritis', 'multiple sclerosis','psoriatic arthritis', 'psoriasis', 'systemic sclerosis', 'spondyloarthritis', 'systemic lupus', 'vasculitis', 'sarcoidosis', 'antiphospholipid syndrome', 'Sjögren syndrome',\n",
    " 'hydroxychloroquine',\n",
    " 'methotrexate',\n",
    " 'leflunomide teriflunomide',\n",
    " '5-ASA',\n",
    " 'azathioprine',\n",
    " 'mercaptopurine',\n",
    " 'mitoxantrone',\n",
    " 'mycophenolate',\n",
    " 'calcineurin inhibitor',\n",
    " 'TNF-α inhibitor',\n",
    " 'fumarates',\n",
    " 'interferons',\n",
    " 'alkylating agent',\n",
    " 'hydroxyurea',\n",
    " 'dapsone',\n",
    " 'cladribine',\n",
    " 'IL-1 inhibitor',\n",
    " 'IL-6 inhibitor',\n",
    " 'IL-12/23 inhibitor',\n",
    " 'IL-17 inhibitor',\n",
    " 'IL-23 inhibitor',\n",
    " 'abatacept',\n",
    " 'anti-BLyS',\n",
    " 'S1P receptor modulator',\n",
    " 'JAK inhibitor',\n",
    " 'integrin inhibitor',\n",
    " 'PDE4i targeted synthetic',\n",
    " 'anti-CD20',\n",
    " 'anti-CD52',\n",
    " 'budesonide',\n",
    " 'systemic glucocorticoids', 'monoclonal antibody covid-19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdcc8b55-c7fe-4bf0-8c50-b2f6fa476cae",
     "showTitle": true,
     "title": "Check and filter out Null rows"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>column_name</th><th>percent_missing</th></tr></thead><tbody><tr><td>hospitalized_after_positive</td><td>0.0</td></tr><tr><td>IMV_after_positive</td><td>0.0</td></tr><tr><td>death_after_positive</td><td>0.0</td></tr><tr><td>age</td><td>0.0</td></tr><tr><td>BMI</td><td>0.0</td></tr><tr><td>sex:male</td><td>0.0</td></tr><tr><td>hypertension</td><td>0.0</td></tr><tr><td>diabetes (type 1+2)</td><td>0.0</td></tr><tr><td>atrial fibrillation</td><td>0.0</td></tr><tr><td>coronary artery disease</td><td>0.0</td></tr><tr><td>heart failure</td><td>0.0</td></tr><tr><td>chronic kidney disease</td><td>0.0</td></tr><tr><td>COPD</td><td>0.0</td></tr><tr><td>chronic liver disease</td><td>0.0</td></tr><tr><td>malignant neoplastic disease</td><td>0.0</td></tr><tr><td>asthma</td><td>0.0</td></tr><tr><td>HIV</td><td>0.0</td></tr><tr><td>history of transplant</td><td>0.0</td></tr><tr><td>stroke</td><td>0.0</td></tr><tr><td>opioid dependence</td><td>0.0</td></tr><tr><td>fully vaccinated</td><td>0.0</td></tr><tr><td>boosted</td><td>0.0</td></tr><tr><td>inflammatory bowel disease</td><td>0.0</td></tr><tr><td>rheumatoid arthritis</td><td>0.0</td></tr><tr><td>multiple sclerosis</td><td>0.0</td></tr><tr><td>psoriatic arthritis</td><td>0.0</td></tr><tr><td>psoriasis</td><td>0.0</td></tr><tr><td>systemic sclerosis</td><td>0.0</td></tr><tr><td>spondyloarthritis</td><td>0.0</td></tr><tr><td>systemic lupus</td><td>0.0</td></tr><tr><td>vasculitis</td><td>0.0</td></tr><tr><td>sarcoidosis</td><td>0.0</td></tr><tr><td>antiphospholipid syndrome</td><td>0.0</td></tr><tr><td>Sjögren syndrome</td><td>0.0</td></tr><tr><td>hydroxychloroquine</td><td>0.0</td></tr><tr><td>methotrexate</td><td>0.0</td></tr><tr><td>leflunomide teriflunomide</td><td>0.0</td></tr><tr><td>5-ASA</td><td>0.0</td></tr><tr><td>azathioprine</td><td>0.0</td></tr><tr><td>mercaptopurine</td><td>0.0</td></tr><tr><td>mycophenolate</td><td>0.0</td></tr><tr><td>calcineurin inhibitor</td><td>0.0</td></tr><tr><td>TNF-α inhibitor</td><td>0.0</td></tr><tr><td>fumarates</td><td>0.0</td></tr><tr><td>interferons</td><td>0.0</td></tr><tr><td>alkylating agent</td><td>0.0</td></tr><tr><td>hydroxyurea</td><td>0.0</td></tr><tr><td>dapsone</td><td>0.0</td></tr><tr><td>IL-6 inhibitor</td><td>0.0</td></tr><tr><td>IL-12/23 inhibitor</td><td>0.0</td></tr><tr><td>IL-17 inhibitor</td><td>0.0</td></tr><tr><td>IL-23 inhibitor</td><td>0.0</td></tr><tr><td>abatacept</td><td>0.0</td></tr><tr><td>S1P receptor modulator</td><td>0.0</td></tr><tr><td>JAK inhibitor</td><td>0.0</td></tr><tr><td>PDE4i targeted synthetic</td><td>0.0</td></tr><tr><td>anti-CD20</td><td>0.0</td></tr><tr><td>budesonide</td><td>0.0</td></tr><tr><td>systemic glucocorticoids</td><td>0.0</td></tr><tr><td>monoclonal antibody covid-19</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "hospitalized_after_positive",
         0.0
        ],
        [
         "IMV_after_positive",
         0.0
        ],
        [
         "death_after_positive",
         0.0
        ],
        [
         "age",
         0.0
        ],
        [
         "BMI",
         0.0
        ],
        [
         "sex:male",
         0.0
        ],
        [
         "hypertension",
         0.0
        ],
        [
         "diabetes (type 1+2)",
         0.0
        ],
        [
         "atrial fibrillation",
         0.0
        ],
        [
         "coronary artery disease",
         0.0
        ],
        [
         "heart failure",
         0.0
        ],
        [
         "chronic kidney disease",
         0.0
        ],
        [
         "COPD",
         0.0
        ],
        [
         "chronic liver disease",
         0.0
        ],
        [
         "malignant neoplastic disease",
         0.0
        ],
        [
         "asthma",
         0.0
        ],
        [
         "HIV",
         0.0
        ],
        [
         "history of transplant",
         0.0
        ],
        [
         "stroke",
         0.0
        ],
        [
         "opioid dependence",
         0.0
        ],
        [
         "fully vaccinated",
         0.0
        ],
        [
         "boosted",
         0.0
        ],
        [
         "inflammatory bowel disease",
         0.0
        ],
        [
         "rheumatoid arthritis",
         0.0
        ],
        [
         "multiple sclerosis",
         0.0
        ],
        [
         "psoriatic arthritis",
         0.0
        ],
        [
         "psoriasis",
         0.0
        ],
        [
         "systemic sclerosis",
         0.0
        ],
        [
         "spondyloarthritis",
         0.0
        ],
        [
         "systemic lupus",
         0.0
        ],
        [
         "vasculitis",
         0.0
        ],
        [
         "sarcoidosis",
         0.0
        ],
        [
         "antiphospholipid syndrome",
         0.0
        ],
        [
         "Sjögren syndrome",
         0.0
        ],
        [
         "hydroxychloroquine",
         0.0
        ],
        [
         "methotrexate",
         0.0
        ],
        [
         "leflunomide teriflunomide",
         0.0
        ],
        [
         "5-ASA",
         0.0
        ],
        [
         "azathioprine",
         0.0
        ],
        [
         "mercaptopurine",
         0.0
        ],
        [
         "mycophenolate",
         0.0
        ],
        [
         "calcineurin inhibitor",
         0.0
        ],
        [
         "TNF-α inhibitor",
         0.0
        ],
        [
         "fumarates",
         0.0
        ],
        [
         "interferons",
         0.0
        ],
        [
         "alkylating agent",
         0.0
        ],
        [
         "hydroxyurea",
         0.0
        ],
        [
         "dapsone",
         0.0
        ],
        [
         "IL-6 inhibitor",
         0.0
        ],
        [
         "IL-12/23 inhibitor",
         0.0
        ],
        [
         "IL-17 inhibitor",
         0.0
        ],
        [
         "IL-23 inhibitor",
         0.0
        ],
        [
         "abatacept",
         0.0
        ],
        [
         "S1P receptor modulator",
         0.0
        ],
        [
         "JAK inhibitor",
         0.0
        ],
        [
         "PDE4i targeted synthetic",
         0.0
        ],
        [
         "anti-CD20",
         0.0
        ],
        [
         "budesonide",
         0.0
        ],
        [
         "systemic glucocorticoids",
         0.0
        ],
        [
         "monoclonal antibody covid-19",
         0.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "column_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "percent_missing",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Columns to drop based on VIF results or missingness\n",
    "# train_pd_df.drop(['HIV'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['systemic sclerosis'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['leflunomide teriflunomide'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['5-ASA'], axis = 1, inplace = True)\n",
    "train_pd_df.drop(['mitoxantrone'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['mycophenolate'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['interferons'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['alkylating agent'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['hydroxyurea'], axis = 1, inplace = True)\n",
    "\n",
    "# train_pd_df.drop(['dapsone'], axis = 1, inplace = True)\n",
    "train_pd_df.drop(['cladribine'], axis = 1, inplace = True)\n",
    "train_pd_df.drop(['IL-1 inhibitor'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['IL-6 inhibitor'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['IL-23 inhibitor'], axis = 1, inplace = True)\n",
    "train_pd_df.drop(['anti-BLyS'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['S1P receptor modulator'], axis = 1, inplace = True)\n",
    "train_pd_df.drop(['integrin inhibitor'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['PDE4i targeted synthetic'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['anti-CD20'], axis = 1, inplace = True)\n",
    "train_pd_df.drop(['anti-CD52'], axis = 1, inplace = True)\n",
    "\n",
    "# train_pd_df.drop(['mercaptopurine'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['abatacept'], axis = 1, inplace = True)\n",
    "\n",
    "# train_pd_df.drop(['IL-1 inhibitor'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['cladribine'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['anti-CD52'], axis = 1, inplace = True)\n",
    "# train_pd_df.drop(['monoclonal antibody covid-19'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "percent_missing = train_pd_df.isnull().sum() * 100 / len(train_pd_df)\n",
    "missing_value_df = pd.DataFrame({'column_name': train_pd_df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "\n",
    "display(missing_value_df)\n",
    "\n",
    "## Notice! Need to comment out once have the initial VIF results\n",
    "## Fill NA values\n",
    "## Method 1: Remove rows with at least one null value\n",
    "# train_pd_noNull_df = train_pd_df.dropna()\n",
    "# train_pd_df = train_pd_noNull_df\n",
    "\n",
    "## Notice\n",
    "## Remove mAbs, antibody feature here\n",
    "train_pd_df.drop(['monoclonal antibody covid-19'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f251342-8bbe-4d9a-a705-77900579e0f4",
     "showTitle": true,
     "title": "Assign X and Y (Feature/Label split)"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current random seed is:  42\ncurrent CV fold selection is:  10\n"
     ]
    }
   ],
   "source": [
    "## manually set the random seed to define a replication\n",
    "r_seed = 42\n",
    "print(\"current random seed is: \", r_seed)\n",
    "\n",
    "## manually set the number for cross validation\n",
    "num_cv = 10\n",
    "print(\"current CV fold selection is: \", num_cv)\n",
    "\n",
    "## Possible response vectors\n",
    "Y_cols = [\"hospitalized_after_positive\", 'IMV_after_positive', 'death_after_positive']\n",
    "\n",
    "## separate X and Y\n",
    "train_df_Y = train_pd_df[Y_cols]\n",
    "train_df_X = train_pd_df.drop(Y_cols, axis=1)\n",
    "\n",
    "## Create composite response vectors\n",
    "train_df_Y_new = pd.DataFrame(train_df_Y, columns = Y_cols)\n",
    "\n",
    "train_df_Y_new['hospitalized_or_IMV_or_death'] = train_df_Y['hospitalized_after_positive'] + train_df_Y['IMV_after_positive'] + train_df_Y['death_after_positive']\n",
    "train_df_Y_new['IMV_or_death'] = train_df_Y['IMV_after_positive'] + train_df_Y['death_after_positive']\n",
    "\n",
    "## Convert those >1 values back to 1\n",
    "train_df_Y_new.loc[train_df_Y_new['hospitalized_or_IMV_or_death'] >= 1, 'hospitalized_or_IMV_or_death'] = 1\n",
    "train_df_Y_new.loc[train_df_Y_new['IMV_or_death'] >= 1, 'IMV_or_death'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35e72f39-63f2-4e3d-a7a7-885061c9dd64",
     "showTitle": true,
     "title": "Check minimum sample sizes for all features"
    }
   },
   "outputs": [],
   "source": [
    "## Notice: LR need a minimum of 10 events (>50 better) per independent variable\n",
    "## Therefore, the following features need to be excluded for lack of events\n",
    "\n",
    "# train_df_X.iloc[:,2:].apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f32fad29-b500-41f7-98b3-4da61fec03c1",
     "showTitle": true,
     "title": "Check multicollinearity with variance inflation factor (VIF)"
    }
   },
   "outputs": [],
   "source": [
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# # VIF dataframe\n",
    "# vif_data = pd.DataFrame()\n",
    "# vif_data[\"feature\"] = train_df_X.columns\n",
    "\n",
    "# # calculating VIF for each feature\n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(train_df_X.values, i) for i in range(len(train_df_X.columns))]\n",
    "\n",
    "# display(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7f173c9-759c-480f-9766-d890f2fd3010",
     "showTitle": true,
     "title": "visualize the data for correlation among the independent variables"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from bioinfokit import visuz\n",
    "\n",
    "# visuz.stat.corr_mat(df=train_df_X, cmap='RdBu',dim = (15,15),  show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9a098d4-6250-4898-a819-1ed58b247e98",
     "showTitle": true,
     "title": "Workaround"
    }
   },
   "outputs": [],
   "source": [
    "## Found workaround at blog: this https://stackoverflow.com/questions/71106940/cannot-import-name-centered-from-scipy-signal-signaltools\n",
    "import  scipy.signal.signaltools\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    newsize = np.asarray(newsize)\n",
    "    currsize = np.array(arr.shape)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "scipy.signal.signaltools._centered = _centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4064a6c-0e79-4f67-a174-786f092e0ee0",
     "showTitle": true,
     "title": "Train multi-variate SVM model (Odds ratio on over sampling and P values on raw samples)"
    }
   },
   "outputs": [],
   "source": [
    "# training a linear SVM classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lxml\n",
    "\n",
    "####################################################################################################\n",
    "## Method used to do univariate logistic regression on each single feature/variable\n",
    "## Inputs:\n",
    "## \n",
    "## Output:\n",
    "## \n",
    "######################################################################################################\n",
    "def multivariate_KNN_model(X_train, y_train, X_test, y_test):\n",
    "  ## Instantiate a bionomial family and logit link function GLM model as logistic regression model\n",
    "  model = KNeighborsClassifier(n_neighbors = 10, weights = 'uniform', algorithm = 'auto').fit(X_train, y_train)\n",
    "  model_binaryclass_auroc = binary_class_roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "  print(\"Auroc on test data set: %0.5f\" % (model_binaryclass_auroc))\n",
    "  \n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32ff2252-0a2b-476a-9686-6794b2571a41",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Response == \"death\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3b4a933-d9eb-447c-aa01-a616344f8768",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique labels from y:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "###############################################################################\n",
    "## Current Y as response\n",
    "## Notice: need manual check\n",
    "## Possible options: hospitalized, invasive_mechanical_vent, death, results\n",
    "################################################################################\n",
    "\n",
    "select_col = 'death_after_positive'\n",
    "Y = train_df_Y[select_col]\n",
    "# Y = Y.map(dict(yes=1, no=0))\n",
    "\n",
    "class_names = np.unique(Y)\n",
    "print(\"unique labels from y: \", class_names)\n",
    "\n",
    "## Train test split use r_seed assigned in CMD 1\n",
    "X = train_df_X\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=r_seed, stratify = Y)\n",
    "columns = X_train.columns\n",
    "\n",
    "## Normalize after the train/test split to avoid any potential data leakage\n",
    "## using the min and max from the trainset to do minmax on test set\n",
    "age_min, age_max = X_train[\"age\"].min(), X_train[\"age\"].max()\n",
    "X_train[\"age\"] = (X_train[\"age\"] - age_min) / (age_max - age_min)\n",
    "X_test[\"age\"] = (X_test[\"age\"] - age_min) / (age_max - age_min)\n",
    "\n",
    "BMI_min, BMI_max = X_train[\"BMI\"].min(), X_train[\"BMI\"].max()\n",
    "X_train[\"BMI\"] = (X_train[\"BMI\"] - BMI_min) / (BMI_max - BMI_min)\n",
    "X_test[\"BMI\"] = (X_test[\"BMI\"] - BMI_min) / (BMI_max - BMI_min)\n",
    "\n",
    "## Random oversampling using random seed\n",
    "## Define oversampling strategy: default, 'auto': equivalent to 'not majority'\n",
    "oversample = RandomOverSampler(random_state=r_seed)\n",
    "os_data_X, os_data_y = oversample.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
    "os_data_y= pd.DataFrame(data=os_data_y, columns=['death_after_positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9525371e-0c17-4dcc-8ef2-cabab380349b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auroc on test data set: 0.71533\n"
     ]
    }
   ],
   "source": [
    "multivariate_KNN_model(os_data_X, os_data_y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b26767b7-7586-464a-af66-96aaab66214d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Response == \"hospitalized_or_IMV_or_death\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd855809-6cc8-44e4-a996-ae7334c3e7be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique labels from y:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "###############################################################################\n",
    "## Current Y as response\n",
    "## Notice: need manual check\n",
    "## Possible options: hospitalized, invasive_mechanical_vent, death, results\n",
    "################################################################################\n",
    "\n",
    "select_col = 'hospitalized_or_IMV_or_death'\n",
    "Y = train_df_Y_new[select_col]\n",
    "# Y = Y.map(dict(yes=1, no=0))\n",
    "\n",
    "class_names = np.unique(Y)\n",
    "print(\"unique labels from y: \", class_names)\n",
    "\n",
    "## Train test split use r_seed assigned in CMD 1\n",
    "X = train_df_X\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=r_seed, stratify = Y)\n",
    "columns = X_train.columns\n",
    "\n",
    "## Normalize after the train/test split to avoid any potential data leakage\n",
    "## using the min and max from the trainset to do minmax on test set\n",
    "age_min, age_max = X_train[\"age\"].min(), X_train[\"age\"].max()\n",
    "X_train[\"age\"] = (X_train[\"age\"] - age_min) / (age_max - age_min)\n",
    "X_test[\"age\"] = (X_test[\"age\"] - age_min) / (age_max - age_min)\n",
    "\n",
    "BMI_min, BMI_max = X_train[\"BMI\"].min(), X_train[\"BMI\"].max()\n",
    "X_train[\"BMI\"] = (X_train[\"BMI\"] - BMI_min) / (BMI_max - BMI_min)\n",
    "X_test[\"BMI\"] = (X_test[\"BMI\"] - BMI_min) / (BMI_max - BMI_min)\n",
    "\n",
    "## Random oversampling using random seed\n",
    "## Define oversampling strategy: default, 'auto': equivalent to 'not majority'\n",
    "oversample = RandomOverSampler(random_state=r_seed)\n",
    "os_data_X, os_data_y = oversample.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
    "os_data_y= pd.DataFrame(data=os_data_y, columns=['hospitalized_or_IMV_or_death'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d39999b-367f-4e02-848c-642af632572c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auroc on test data set: 0.63832\n"
     ]
    }
   ],
   "source": [
    "multivariate_KNN_model(os_data_X, os_data_y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90223830-afce-493c-8589-26ce6191d19d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Response == \"IMV_or_death\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74db3717-0189-4a42-91fa-913b758089e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique labels from y:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "###############################################################################\n",
    "## Current Y as response\n",
    "## Notice: need manual check\n",
    "## Possible options: hospitalized, invasive_mechanical_vent, death, results\n",
    "################################################################################\n",
    "\n",
    "select_col = 'IMV_or_death'\n",
    "Y = train_df_Y_new[select_col]\n",
    "# Y = Y.map(dict(yes=1, no=0))\n",
    "\n",
    "class_names = np.unique(Y)\n",
    "print(\"unique labels from y: \", class_names)\n",
    "\n",
    "## Train test split use r_seed assigned in CMD 1\n",
    "X = train_df_X\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=r_seed, stratify = Y)\n",
    "columns = X_train.columns\n",
    "\n",
    "## Normalize after the train/test split to avoid any potential data leakage\n",
    "## using the min and max from the trainset to do minmax on test set\n",
    "age_min, age_max = X_train[\"age\"].min(), X_train[\"age\"].max()\n",
    "X_train[\"age\"] = (X_train[\"age\"] - age_min) / (age_max - age_min)\n",
    "X_test[\"age\"] = (X_test[\"age\"] - age_min) / (age_max - age_min)\n",
    "\n",
    "BMI_min, BMI_max = X_train[\"BMI\"].min(), X_train[\"BMI\"].max()\n",
    "X_train[\"BMI\"] = (X_train[\"BMI\"] - BMI_min) / (BMI_max - BMI_min)\n",
    "X_test[\"BMI\"] = (X_test[\"BMI\"] - BMI_min) / (BMI_max - BMI_min)\n",
    "\n",
    "## Random oversampling using random seed\n",
    "## Define oversampling strategy: default, 'auto': equivalent to 'not majority'\n",
    "oversample = RandomOverSampler(random_state=r_seed)\n",
    "os_data_X, os_data_y = oversample.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
    "os_data_y= pd.DataFrame(data=os_data_y, columns=['IMV_or_death'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "343e1433-b2ec-4fc5-a942-5908aa3070eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auroc on test data set: 0.70139\n"
     ]
    }
   ],
   "source": [
    "multivariate_KNN_model(os_data_X, os_data_y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c8cc9ca-3748-4f65-8135-c675315628a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Step3.1.1.multi_KNN_analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
